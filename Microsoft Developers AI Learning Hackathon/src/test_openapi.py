"""Test the Azure OpenAI API."""

# Standard Library
import os

# Third Party
from dotenv import load_dotenv
from openai import AzureOpenAI

load_dotenv()


def main() -> None:
    """Test the Azure OpenAI API."""

    try:
        ENDPOINT = os.getenv("proxy_endpoint")
        API_KEY = os.getenv("api_key")
        MODEL_NAME = "gpt-35-turbo"
        API_VERSION = "2024-02-01"

        # Setup the Azure OpenAI client
        client = AzureOpenAI(
            azure_endpoint=ENDPOINT,
            api_key=API_KEY,
            api_version=API_VERSION,
        )

        # Setup System messages
        system_message = """
        You are a helpful assistant.
        You provide a note at end of the conversation stating "This response is generated by an AI assistant setup by Keys.".
        """

        # Setup the message list (history of the conversation)
        message_list = [{"role": "system", "content": system_message}]

        while True:
            # Get the user input
            user_input = input("Enter the prompt (or type 'exit' to quit): ")
            if user_input.lower() == "exit":
                break
            elif user_input == "":
                print("Please enter a valid prompt.")
                continue

            # Append the user input to the message list
            message_list.append({"role": "user", "content": user_input})

            # Get the completion
            completion = client.chat.completions.create(
                model=MODEL_NAME,
                messages=message_list,
                temperature=0.7,
                max_tokens=1200,
            )

            # Get the response
            response = completion.choices[0].message.content
            print(f"Response: {response}")

            # Append the response to the message list
            message_list.append({"role": "assistant", "content": response})

    except Exception as error:
        print(f"Error: {error}")


if __name__ == "__main__":
    main()
